{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca40aa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4460d6f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import torchvision\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395bc036",
   "metadata": {},
   "source": [
    "# Load Model\n",
    "**Load pretrained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8667e140",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastRCNNPredictor(\n",
       "  (cls_score): Linear(in_features=1024, out_features=91, bias=True)\n",
       "  (bbox_pred): Linear(in_features=1024, out_features=364, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.roi_heads.box_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9d79c20",
   "metadata": {},
   "source": [
    "**Change Last Layer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "962b1312",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FastRCNNPredictor(\n",
       "  (cls_score): Linear(in_features=1024, out_features=11, bias=True)\n",
       "  (bbox_pred): Linear(in_features=1024, out_features=44, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_classes = 11\n",
    "in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "model.roi_heads.box_predictor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01523da1",
   "metadata": {},
   "source": [
    "# Load Dataset\n",
    "**Create dataset wrapper**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64a2c80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "import pathlib\n",
    "from xml.etree import ElementTree\n",
    "\n",
    "import torch\n",
    "import torchvision.transforms\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "\n",
    "class ATZDataset(Dataset):\n",
    "    \"\"\"\n",
    "    The data_dir directory must contain:\n",
    "        JPEGImages\n",
    "        Annotations\n",
    "        train.txt\n",
    "        test.txt\n",
    "        val.txt\n",
    "    to provide Active Terahertz Imaging Dataset for Concealed Object Detection(https://github.com/LingLIx/THz_Dataset)\n",
    "    \"\"\"\n",
    "    ATZ_CLASSES = [\"CP\", \"MD\", \"GA\", \"KK\", \"SS\",\n",
    "                   \"KC\", \"WB\", \"LW\", \"CK\", \"CL\", \"UNKNOWN\", \"UN\"]\n",
    "    IGNORE_CLASSES = [\"HUMAN\", ]\n",
    "    \n",
    "    def __init__(self, root: str, split: str):\n",
    "        assert split in (\"train\", \"test\", \"val\")\n",
    "        self.data_dir = pathlib.Path(root)\n",
    "        self.image_dir = self.data_dir / \"JPEGImages\"\n",
    "        self.anno_dir = self.data_dir / \"Annotations\"\n",
    "        self.collection_file = self.data_dir / (\"%s.txt\" % split)\n",
    "        assert os.path.isdir(self.data_dir)\n",
    "        assert os.path.isdir(self.image_dir)\n",
    "        assert os.path.isdir(self.anno_dir)\n",
    "        assert os.path.isfile(self.collection_file)\n",
    "        # load filenames form split files\n",
    "        with open(self.collection_file) as fp:\n",
    "            self.filenames = list(map(lambda x: x.strip(), fp.readlines()))\n",
    "    \n",
    "    def read_vocxml_content(self, xml_file: str):\n",
    "        tree = ElementTree.parse(xml_file)\n",
    "        root = tree.getroot()\n",
    "        OOI = list(filter(lambda _box: _box.find(\"name\").text not in self.IGNORE_CLASSES, root.iter('object')))\n",
    "        N = len(OOI)\n",
    "        boxes = torch.zeros((N, 4), dtype=torch.float32)\n",
    "        labels = torch.zeros((N,), dtype=torch.int64)\n",
    "        for idx, box in enumerate(OOI):\n",
    "            class_ = box.find(\"name\").text\n",
    "            ymin = int(box.find(\"bndbox/ymin\").text)\n",
    "            xmin = int(box.find(\"bndbox/xmin\").text)\n",
    "            ymax = int(box.find(\"bndbox/ymax\").text)\n",
    "            xmax = int(box.find(\"bndbox/xmax\").text)\n",
    "            boxes[idx, :] = (xmin, ymin, xmax, ymax)\n",
    "            labels[idx] = self.ATZ_CLASSES.index(class_)\n",
    "        return dict(boxes=boxes, labels=labels)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.filenames[idx]\n",
    "        print(filename)\n",
    "        image = torchvision.transforms.ToTensor()(Image.open(self.image_dir / (\"%s.jpg\" % filename)).convert(\"RGB\"))\n",
    "        targets = self.read_vocxml_content(self.anno_dir / (\"%s.xml\" % filename))\n",
    "        return image, targets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e643ce8a",
   "metadata": {},
   "source": [
    "**Create dataloader function by split**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "68cab4dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "def get_dataloader(split):\n",
    "    \"\"\"\n",
    "    Returns dataloader for given split\n",
    "    \"\"\"\n",
    "    batch_size = 32\n",
    "    drop_last = True\n",
    "    num_workers = 4\n",
    "    data_dir = \"data/THZ_dataset/THZ_dataset_det_VOC\"\n",
    "    dataset = ATZDataset(root=data_dir, split=split)\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            drop_last=drop_last,\n",
    "                            shuffle=True, num_workers=num_workers)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48377d1a",
   "metadata": {},
   "source": [
    "# Train Loop\n",
    "**initialize optimiser**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be17108a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor\n",
    "\n",
    "\n",
    "\n",
    "def get_dataloader(split):\n",
    "    batch_size = 32\n",
    "    drop_last = True\n",
    "    num_workers = 4\n",
    "    data_dir = \"data/THZ_dataset/THZ_dataset_det_VOC\"\n",
    "    dataset = ATZDataset(root=data_dir, split=split)\n",
    "    dataloader = DataLoader(dataset=dataset, batch_size=batch_size,\n",
    "                            drop_last=drop_last,\n",
    "                            shuffle=True, num_workers=num_workers)\n",
    "    return dataloader\n",
    "\n",
    "\n",
    "def get_net(num_classes):\n",
    "    \"\"\"\n",
    "    Returns:\n",
    "    https://pytorch.org/vision/stable/models/generated/torchvision.models.detection.fasterrcnn_resnet50_fpn.html\n",
    "    #torchvision.models.detection.fasterrcnn_resnet50_fpn\n",
    "    \"\"\"\n",
    "    model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = FastRCNNPredictor(in_features, num_classes)\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_optimizers(net, lr=0.001):\n",
    "    optimizer = optim.RMSprop(net.parameters(), lr=lr)\n",
    "    return optimizer\n",
    "\n",
    "\n",
    "def training(net, optimizer, device, max_epoch=5, start_epoch=0):\n",
    "    train_dataloader = get_dataloader('train')\n",
    "    # device = torch.device('cpu')\n",
    "    \n",
    "    net.train()\n",
    "    net.to(device)\n",
    "    for epoch_idx in range(start_epoch, max_epoch, 1):\n",
    "        for batch_idx, (batch_image, batch_targets) in enumerate(train_dataloader):\n",
    "            print(\"\\rEpoch [%d/%d] Batch [%d/%d] \"%(epoch_idx,max_epoch,), end=\"\\b\")\n",
    "            # transfer data to GPU\n",
    "            batch_image.to(device)\n",
    "            batch_targets.to(device)\n",
    "            # Forward pass with loss\n",
    "            optimizer.zero_grad()\n",
    "            losses = net(batch_image, batch_targets)\n",
    "            # sum classification loss + bbox regression loss\n",
    "            loss = sum(v for v in losses.values())\n",
    "            # set gradient to zero\n",
    "            # Calculate gradient\n",
    "            loss.backword()\n",
    "            # update parameters\n",
    "            optimizer.step()\n",
    "        print(\"Loss:\", loss.detach().cup())\n",
    "\n",
    "\n",
    "def testing(net, optimizer):\n",
    "    test_dataloader = get_dataloader('test')\n",
    "    ...\n",
    "\n",
    "\n",
    "def validation(net):\n",
    "    val_dataloader = get_dataloader('val')\n",
    "    ...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83311230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    max_epoch = 5\n",
    "    start_epoch = 0\n",
    "    num_classes = 11\n",
    "    lr = 0.001\n",
    "    device = torch.device('cpu')\n",
    "    net = get_net(num_classes=num_classes)\n",
    "    optimizer = get_optimizers(net, lr=lr)\n",
    "    training(net, optimizer,device, max_epoch=5, start_epoch=0)\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ce4da4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".mlops",
   "language": "python",
   "name": ".mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
