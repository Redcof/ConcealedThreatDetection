name: cdt
experiment_description: Saving live progress. Early stopping. Model saving scheduler. Per model I/O signature for mlflow log_model()
exp_name_postfix: IP-10.73.24.37
random_seed: 47
dataset:
  name: atz
  voc_data: True
  data_root: ./data/THZ_dataset/THZ_dataset_det_VOC
  class_file: ./data/THZ_dataset/THZ_dataset_det_VOC/classes.txt
framework: pytorch
model:
  name: fasterrcnn_resnet50_fpn
  weights: None
train:
  flag: True
  batch_size: 16
  optimizer:
    name: Adam
  lr: 0.001
  lr_schedule_warmup_epoch: 1
  lr_schedule:
    flag: False
    name: LinearLR
    start_factor: 1
    total_iters: 2
  start_epoch: 1
  max_epoch: 100
  finetune:
    flag: True
    checkpoint_path: ''
  save_schedule: # config when to save/log model
    type: metric # [epoch: epoch intervals, metric: highest performance, loss: lowest loss, otherwise save it at the end of training]
    key: test_map_70 # [if type=epoch, key=<integer>, if type=metric, key=<metric_name>, if type=loss, key=<loss_name>(in case we have multiple losses)]
    value_delta: 0.02 # [an increase threshold of performance and a decrease loss to log the model]
    # Provide saving frequency,
  metrics: MeanAveragePrecision
inference:
  flag: False
  checkpoint_path: ''
